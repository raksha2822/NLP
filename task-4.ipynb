{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f5fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8a2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://gutenberg.org/files/98/98-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990ff6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929d7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b01fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293d2b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'A', 'Tale', 'of', 'Two', 'Cities', ',', 'by', 'Charles', 'Dickens', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'A', 'Tale', 'of', 'Two', 'Cities', 'A', 'Story', 'of', 'the', 'French', 'Revolution', 'Author', ':', 'Charles', 'Dickens', 'Release', 'Date', ':', 'January', ',', '1994', '[', 'eBook', '#', '98', ']', '[', 'Most', 'recently', 'updated', ':', 'December', '20', ',', '2020', ']', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', 'Produced', 'by', ':', 'Judith', 'Boss', 'and', 'David', 'Widger', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'A', 'TALE', 'OF', 'TWO', 'CITIES', '*', '*', '*', 'A', 'TALE', 'OF', 'TWO', 'CITIES', 'A', 'STORY', 'OF', 'THE', 'FRENCH', 'REVOLUTION', 'By', 'Charles', 'Dickens', 'CONTENTS', 'Book', 'the', 'First', '--', 'Recalled', 'to', 'Life', 'CHAPTER', 'I', 'The', 'Period', 'CHAPTER', 'II']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76379246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup\n",
    "#Preprocession - RE to clean any html tags or unnecessary char sequences\n",
    "#PoS Tagging\n",
    "#!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75df429b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "porter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85feeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "lancaster.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebf1ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import RegexpStemmer\n",
    "regexp = RegexpStemmer('ing$')\n",
    "regexp.stem('singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eae19a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frau'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('german')\n",
    "snowball.stem('frauen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361a13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed = []\n",
    "for i in range(0, 50):\n",
    "    porter = PorterStemmer()\n",
    "    stemmed.append(porter.stem(tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce7dd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffthe', 'project', 'gutenberg', 'ebook', 'of', 'a', 'tale', 'of', 'two', 'citi', ',', 'by', 'charl', 'dicken', 'thi', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyon', 'anywher', 'in', 'the', 'unit', 'state', 'and', 'most', 'other', 'part', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrict', 'whatsoev', '.', 'you', 'may', 'copi', 'it', ',', 'give']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78d81cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "text = \"There were about twenty people on the dam. Most of them were simply walking and getting exercise. There were a few who were fishing. There was a family who had laid down a blanket and they were having a picnic. It was like this most days and nothing seemed out of the ordinary. The problem was that nobody noticed the water leaking through the dam wall.\"\n",
    "stemmed = [porter.stem(token) for token in text.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e8d9f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'were', 'about', 'twenti', 'peopl', 'on', 'the', 'dam.', 'most', 'of', 'them', 'were', 'simpli', 'walk', 'and', 'get', 'exercise.', 'there', 'were', 'a', 'few', 'who', 'were', 'fishing.', 'there', 'wa', 'a', 'famili', 'who', 'had', 'laid', 'down', 'a', 'blanket', 'and', 'they', 'were', 'have', 'a', 'picnic.', 'it', 'wa', 'like', 'thi', 'most', 'day', 'and', 'noth', 'seem', 'out']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c87827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus\n",
      "be\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "print(lemma.lemmatize('cacti'))\n",
    "print(lemma.lemmatize('am', pos = 'v'))\n",
    "print(lemma.lemmatize('better', pos = 'a'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
